{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True # change to False if not using gpu\n",
    "num_epochs = 20\n",
    "batch_size = 30\n",
    "num_workers = 12\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training dataset and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_means = [129.3, 124.1,112.4]\n",
    "channel_stds = [68.2, 65.4,70.4]\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize(512),\n",
    "        transforms.RandomCrop(512),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[n / 255. for n in channel_means],\n",
    "                             std=[n / 255. for n in channel_stds])])\n",
    "\n",
    "train_dataset=datasets.ImageFolder(root=\"data/train/\",transform=train_transform)\n",
    "trainLoader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features,100)\n",
    "\n",
    "if use_gpu:\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    for i, data in enumerate(trainLoader,0):\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = torch.squeeze(model(inputs))\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test data.\n",
    "\n",
    "Note: this is fairly inefficient as it only loads one image as a time. Could be improved by implementing a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ground_truth = pd.read_csv('data/test_data.csv')\n",
    "test_folder = 'data/test/'\n",
    "gt_files = np.array([os.path.join(test_folder,t.strip()) for t in test_ground_truth['filename']]) # the test_data file seems to have spaces in the filenames\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(512),\n",
    "        transforms.CenterCrop(512),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[n / 255. for n in channel_means],\n",
    "                             std=[n / 255. for n in channel_stds])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "pred_classes = []\n",
    "gt_classes = []\n",
    "all_outputs = []\n",
    "with torch.no_grad():\n",
    "    for im in gt_files: \n",
    "        img = Image.open(im)\n",
    "        inputs = test_transform(img).unsqueeze(0)\n",
    "        if use_gpu:\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "        outputs = torch.squeeze(model(inputs))\n",
    "        if use_gpu:\n",
    "            outputs = outputs.detach().cpu()\n",
    "        \n",
    "        all_outputs.append(outputs.numpy())\n",
    "        \n",
    "        pred_class = train_dataset.classes[outputs.argmax()]\n",
    "        pred_classes.append(pred_class)\n",
    "        \n",
    "        gt_class = test_ground_truth.iloc[np.where(gt_files==im.split('/')[-1])[0][0]]['cultivar'].strip()\n",
    "        gt_classes.append(gt_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = [p==g for p,g in zip(pred_classes, gt_classes)]\n",
    "accuracy = sum(is_correct) / len(results)\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
